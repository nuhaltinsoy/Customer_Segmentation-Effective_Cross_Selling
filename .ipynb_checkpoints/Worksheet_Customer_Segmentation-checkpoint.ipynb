{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation\n",
    "# What is Cohort Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is a descriptive analytics tool\n",
    "\n",
    "* It groups the customers into Mutually Exclusive Cohorts(segments)\n",
    "\n",
    "* It provides depper insights than the so-called vanity metrics\n",
    "\n",
    "* Compare metrics across product lifecycle \n",
    "\n",
    "* Compare metrics across customer lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Time Cohorts:\n",
    "\n",
    "Time cohorts are customers who signed up for a product or service during a particular time frame. Analyzing these cohorts shows the customers' behavior depending on the time they started using the company's products or services. The time may be monthly, quarterly, even daily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.Behavior Cohorts: \n",
    "\n",
    "Behavior cohorts are customers who purchased a product or subscribed to a service in the past. It groups customers by the type of product or service they signed up. Customers who signed up for basic level services might have different needs than those who signed up for advanced services. Understanding the needs of the various cohorts can help a company design custom-made services or products for particular segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.Size Cohorts: \n",
    "\n",
    "Size cohorts refer to the various sizes of customers who purchase company's products or services. This categorization can be based on the amount of spending in some period of time after acquisition, or the product type that the customer spent most of their order amount in some period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elements of Cohort Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Pivot Table:** \n",
    "\n",
    "The cohort analysis data is typically formatted as a pivot table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Assigned cohort in rows:** \n",
    "\n",
    "The row values represent the cohort. In our example, it is the month of the first purchase and customers are pooled into these groups based on their first ever purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cohort index in columns:** \n",
    "\n",
    "The column values represent months since acquisition. It can be measured in other time periods like months, days, even hours or minutes. That depends the scope of analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Metrics in the table:** \n",
    "\n",
    "Here, we have the count of active customers. The first column with cohort index \"one\" represents the total number of customers in that cohort. This is the month of their first transcation. We will use this data in the next lessons to calculate the retention rate and other metrics.\n",
    "\n",
    "Let's look at the table- we can see that the first cohort was acquired in December 2010, there are 715 cuctomers in it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Cohorts Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a function that truncates a given date object to a first day of the month. In another word,  create a function by passing a datetime object extracting year, month and day from x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(x): return dt.datetime(x.year, x.month,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Then we apply it to the InvoiceDate and create an InvoiceMonth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online['InvoiceMonth'] = online['InvoiceDate'].apply(get_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We create a groupby() object with CustomerID and use the InvoiceMonth column for the further manipulation. (Group by CustomerID and select the InvoiceMonth value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping = online.groupby('CustomerID')['InvoiceMonth'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Finally, we use transform() together with a min() function to assign the smallest InvoiceMonth value to each customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online['CohortMonth'] = grouping.transform('min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2 (calculate the time offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define a function to extract year, month and day integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_int(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will calculate the number of months between any transaction and the first transaction for each customer. We will use InvoiceMonth and CohortMonth values to do this. We will start by creating two object with year and month integer values from each of the InvoiceMonth and CohortMonth variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_year, invoice_month, _=get_date_int(online, 'InvoiceMonth')\n",
    "cohort_year, cohort_month, _=get_date_int(online, 'CohortMonth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will calculate the differences in years and months between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_diff = invoice_year - cohort_year\n",
    "months_diff = invoice_month - cohort_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will convert the total differences to months by multiplying the year difference by 12 and adding them together. You can see, there is a \"+1\" in the end. We do this so the first month is marked as 1 instead of 0 for easier interpretation. You can see that the new column is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online['CohortIndex'] = years_diff * 12 + months_diff + 1\n",
    "online.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Calculate the number of monthly active customers in each cohort and make the cohort counts table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's pull some metrics: we will calculate the number of monthly active customers in each cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a groupby object with CohortMonth and CohortIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping  = online.groupby([CohortMonth] , [CohortIndex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will count number of customers in each group by applying pandas nunique() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_data = grouping['CustomerID'].apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_data = cohort_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pandas pivot with CohortMonth in the rows, CohortIndex in the columns and CustomerID counts as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_counts = cohort_data.pivot( index= 'CohortMonth'\n",
    "                                   columns= 'CohortIndex'\n",
    "                                   values= 'CustomerID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a table that will serve as the basis for the rest of this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Calculate Cohort Metrics (customer retention rate table and the average purchase quantity table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retention** \n",
    "Retention measures how many customers from each of the cohort returned in the subsequent months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retention Rate \n",
    "The ratio of how many customers came back in the subsequent months.\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store the first column as cohort_sizes\n",
    "\n",
    "cohort_sizes = cohort_counts.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the divide() function on the cohort_counts dataframe and pass the cohort_sizes.\n",
    "# We set the axis parameter to zero to ensure that we divide along the row axis\n",
    "\n",
    "# Divide all values in the cohort_counts table by cohort_sizes\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We round the ratio to 3 digits and multiply it by a 100 to make it look like a percentage.\n",
    "\n",
    "# Review the retention table\n",
    "retention.round(3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can examine our retention table. As you can see, the first column has a 100% retention rate for all cohorts, as expected. We can compare the retention rate over time and across cohorts to evaluate the health of our customer's shopping habits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Average quantity** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a groupby () object with CohortMonth and CohortIndex and store it as grouping.\n",
    "\n",
    "grouping = online.groupby(['CohortMonth', 'CohortIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we call grouping object, select the Quantity column and calculate the average and we store the results as cohort_data\n",
    "\n",
    "cohort_data = grouping['Quantity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we reset the index before calling the pivot function to be able to access the columns now stored as indices\n",
    "\n",
    "cohort_data = cohort_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we create a pivot table by passing CohortMonth to the index parameter, CohortIndex to the colmuns parameter, and the Quantity to the values parameter.\n",
    "\n",
    "average_quantity = cohort_data.pivot(index= 'CohortMonth',\n",
    "                                     columns='CohortIndex',\n",
    "                                     values='Quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round it up to 1 digit.\n",
    "\n",
    "average_quantity.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are fully equipped to manipulate transactional customer data and draw powerful insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Cohort Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral customer segmentation based on three metrics:\n",
    "   **RFM (Recency, Frequency, Monetary Value) Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Recency (R): \n",
    "**How recent was each customer's last purchase, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Frequency (F):\n",
    "\n",
    "**How many purchases the customer has done in the last 12 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Monetary Value (M):\n",
    "** how much has the customer spent in the last 12 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these values to assign customers to RFM segments. Once we calculated these numbers, the next step is to group them into some sort of categorization such as high, medium and low.\n",
    "There are multiple ways to do that. We can break customers into groups of equal size based on;\n",
    "\n",
    "> Percentiles e.g. quantiles: percentile values of each metric.\n",
    "\n",
    "> Pareto 80/20 cut: We can assign either high or low value to each metric based on a 80/20 % Pareto split. \n",
    "\n",
    "> Custom - based on business knowledge: we can use existing knowledge from previous business insights about certain threshold values for each metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will learn how to assign a percentile to a metric, and then create a label to be used for segmentation. \n",
    "\n",
    "The process of calculating percentiles is fairly simple: \n",
    "> First, you sort the customers based on that metric, \n",
    "\n",
    "> Then, you break the customers into a number of groups that you think is relevant. The groups are equal in size. \n",
    "\n",
    "> Finally, you assign a label to each group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, in pandas we already have a function bulit in for calculating percentiles called qcut().To understand the concepts behind percentile calculations- we have cretaed a simple dataset with 8 customerIDs and random Spend values representing their total spend with the company. We will now assign a quartile value to each of these customers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will use the qcut() function on the Spend Variable and define 4 groups of equa; sizes-called quartiles.\n",
    "\n",
    "We will also pass a range() function to the labels argument so our groups have integer names, with highest value quartile labeled as 4, and lowest as 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_quartiles = pd.qcut(data['spend'], q=4, labels = range (1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a column to our dataframe.And then we print it after sorting by the quartile value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Spend_Quartile'] = spend_quartiles\n",
    "\n",
    "data.sort_values('Spend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When assigning labels we want them to represent what is the top and the bottom percentile based on sorted values, but the highest value of the metric is not always the best. For example the recency metric which calculates days since the last purchase, is better when it is low rather than high. For this example, we have created a sample dataset with 8 CustomerIDs and their Recency in days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a list of labels-only this time the values are reversed as lower recency is rated higher.\n",
    "\n",
    "r_labels = list(range(4, 0, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use the qcut() function on the Recency Variable, and define that we want 4 groups of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into groups based on quartiles\n",
    "\n",
    "recency_quartiles = pd.qcut(data['Recency_Days'], q=4, labels=r_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a column to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column\n",
    "\n",
    "data['Recency_Quartile'] = recency_quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort recency values from lowest to highest\n",
    "\n",
    "data.sort_values('Recency_Days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code prins the table. As you can see in the table, the lower the recency, the higher the quartile value (the quartile labels are reveersed, since the more recent customers are more valuable). When assigning labels, you should always think whether higher or lower values should be of a higher rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Labels:**\n",
    "\n",
    "we can also create custom named labels. (we can define a list with string or any other values, depending on the use case.)\n",
    "\n",
    "First, we create named labels as strings in a descending order. We use descending order beacuse we are ranking Recency metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create string labels\n",
    "\n",
    "r_labels = ['Active', 'Lapsed', 'Inactive', 'Churned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into groups based on quartiles\n",
    "\n",
    "recency_quartiles = pd.qcut(data['Recency_Days'], q=4, labels=r_labels)\n",
    "\n",
    "# create new column\n",
    "\n",
    "data['Recency_Quartile'] = recency_quartiles\n",
    "\n",
    "# sort values from lowest to highest\n",
    "\n",
    "data.sort_values('Recency_Days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this is a small sample, it does show the main concepts of how to use percentiles to group customers based on their usage behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New TotalSum column = Quantity * UnitPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Min:{}; Max:{}'). format (min(online.InvoiceDate),\n",
    "                                  max(online.InvoiceDate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a hypothetical snapshot_day data as if we're doing analysis recently\n",
    "# en son yapilan satis uzerine 1 gun ekliyoruz...\n",
    "snapshot_date = max(online.InvoiceDate) + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data on a customer level\n",
    "datamart = online.groupby(['CustomerID']).agg({'InvoiceDate' : lambda x: (snapshot_date - x.max()).days,\n",
    "                                               'InvoiceNo': 'count',\n",
    "                                               'TotalSum' : 'sum'})\n",
    "# Rename columns for easier interpretation\n",
    "datamart.rename(columns = {'InvoiceDate': 'Recency',\n",
    "                           'InvoiceNo': 'Frequency',\n",
    "                           'TotalSum': 'MonetaryValue'}, inplace=True)\n",
    "\n",
    "# Check the first rows\n",
    "datamart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Cohort Example_Part-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign daily acquisition cohort:\n",
    "\n",
    "As you have seen in the video, defining a cohort is the first step to cohort analysis. You will now create daily cohorts based on the day each customer has made their first transaction.\n",
    "\n",
    "DataFrame's name is online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will parse the date\n",
    "def get_day(x): return dt.datetime(x.year, x.month, x.day) \n",
    "\n",
    "# Create InvoiceDay column\n",
    "online['InvoiceDay'] = online['InvoiceDate'].apply(get_day) \n",
    "\n",
    "# Group by CustomerID and select the InvoiceDay value\n",
    "grouping = online.groupby('CustomerID')['InvoiceDay'] \n",
    "\n",
    "# Assign a minimum InvoiceDay value to the dataset\n",
    "online['CohortDay'] = grouping.transform('min')\n",
    "\n",
    "# View the top 5 rows\n",
    "print(online.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate time offset in days - part 1**\n",
    "Calculating time offset for each transaction allows you to report the metrics for each cohort in a comparable fashion.\n",
    "\n",
    "First, we will create 6 variables (invoice_year, invoice_month, invoice_day, cohort_year, cohort_month, cohort_day)  that capture the integer value of years, months and days for Invoice and Cohort Date using the get_date_int() function that's been already defined for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_date_int() function is already created   \n",
    "def get_date_int(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the integers for date parts from the `InvoiceDay` column\n",
    "invoice_year, invoice_month, invoice_day = get_date_int(online, 'InvoiceDay')\n",
    "\n",
    "# Get the integers for date parts from the `CohortDay` column\n",
    "cohort_year, cohort_month, cohort_day = get_date_int(online, 'CohortDay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate time offset in days - part 2**\n",
    "Great work! Now, we have six different data sets with year, month and day values for Invoice and Cohort dates - invoice_year, cohort_year, invoice_month, cohort_month, invoice_day, and cohort_day.\n",
    "\n",
    "In this exercise you will calculate the difference between the Invoice and Cohort dates in years, months and days separately and then calculate the total days difference between the two. This will be your days offset which we will use in the next exercise to visualize the customer count. The online data has been loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference in years\n",
    "years_diff = invoice_year - cohort_year\n",
    "\n",
    "# Calculate difference in months\n",
    "months_diff = invoice_month - cohort_month\n",
    "\n",
    "# Calculate difference in days\n",
    "days_diff = invoice_day - cohort_day\n",
    "\n",
    "# Extract the difference in days from all previous values\n",
    "# Calculate the number of days for the CohortIndex (assume 365 days in a year, and 30 days in a month).\n",
    "\n",
    "online['CohortIndex'] = years_diff * 365 + months_diff * 12 + days_diff + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Cohort Example_Part-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customer retention** is a very useful metric to understand how many of the all customers are still active. Which of the following best describes customer retention?\n",
    "\n",
    "**Retention** gives you the percentage of active customers compared to the total number of customers.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate retention rate from scratch**\n",
    "\n",
    "You have seen how to create retention and average quantity metrics table for the monthly acquisition cohorts. Now it's you time to build the retention metrics by yourself.\n",
    "\n",
    "The online dataset has been loaded to you with monthly cohorts and cohort index assigned from this lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping = online.groupby(['CohortMonth', 'CohortIndex'])\n",
    "\n",
    "# Count the number of unique values per customer ID\n",
    "cohort_data = grouping['CustomerID'].apply(pd.Series.nunique).reset_index()\n",
    "\n",
    "# Create a pivot \n",
    "cohort_counts = cohort_data.pivot(index='CohortMonth', columns='CohortIndex', values='CustomerID')\n",
    "\n",
    "# Select the first column and store it to cohort_sizes\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "\n",
    "# Divide the cohort count by cohort sizes along the rows\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate average price**\n",
    "\n",
    "You will now calculate the average price metric and analyze if there are any differences in shopping patterns across time and across cohorts.\n",
    "\n",
    "The online dataset has been loaded to you with monthly cohorts and cohort index assigned from this lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a groupby object and pass the monthly cohort and cohort index as a list\n",
    "grouping = online.groupby(['CohortMonth', 'CohortIndex']) \n",
    "\n",
    "# Calculate the average of the unit price \n",
    "cohort_data = grouping['UnitPrice'].mean()\n",
    "\n",
    "# Reset the index of cohort_data\n",
    "cohort_data = cohort_data.reset_index()\n",
    "\n",
    "# Create a pivot \n",
    "average_quantity = cohort_data.pivot(index='CohortMonth', columns='CohortIndex', values='UnitPrice')\n",
    "print(average_quantity.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Cohort Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a dataset for you with random CustomerID and Spend values as data. You will now use this dataset to group customers into quartiles based on Spend values and assign labels to each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "\n",
    "    CustomerID  Spend\n",
    "0           0    137\n",
    "1           1    335\n",
    "2           2    172\n",
    "3           3    355\n",
    "4           4    303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spend quartile with 4 groups - a range between 1 and 5\n",
    "spend_quartile = pd.qcut(data['Spend'], q=4, labels=range(1,5))\n",
    "\n",
    "# Assign the quartile values to the Spend_Quartile column in data\n",
    "data['Spend_Quartile'] = spend_quartile\n",
    "\n",
    "# Print data with sorted Spend values\n",
    "print(data.sort_values('Spend'))\n",
    "\n",
    "#You have assigned spend quartiles to each customer with numeric labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     CustomerID Spend     Spend_Quartile\n",
    "0           0    137              1\n",
    "2           2    172              1\n",
    "7           7    229              2\n",
    "5           5    233              2\n",
    "6           6    244              3\n",
    "4           4    303              3\n",
    "1           1    335              4\n",
    "3           3    355              4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store labels from 4 to 1 in a decreasing order\n",
    "r_labels = list(range(4, 0, -1))\n",
    "\n",
    "# Create a spend quartile with 4 groups and pass the previously created labels \n",
    "recency_quartiles = pd.qcut(data['Recency_Days'], q=4, labels=r_labels)\n",
    "\n",
    "# Assign the quartile values to the Recency_Quartile column in `data`\n",
    "data['Recency_Quartile '] = recency_quartiles \n",
    "\n",
    "# Print `data` with sorted Recency_Days values\n",
    "print(data.sort_values('Recency_Days'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      CustomerID  Recency_Days     Recency_Quartile \n",
    "0           0            37                 4\n",
    "3           3            72                 4\n",
    "7           7           133                 3\n",
    "6           6           203                 3\n",
    "1           1           235                 2\n",
    "4           4           255                 2\n",
    "5           5           393                 1\n",
    "2           2           396                 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You have successfully calculated recency quartiles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Recency, Frequency and Monetary values for the online dataset we have used before - it has been loaded for you with recent 12 months of data. There's a TotalSum column in the online dataset which has been calculated by multiplying Quantity and UnitPrice: online['Quantity'] * online['UnitPrice'].\n",
    "\n",
    "Also, we have created a snapshot_date variable that you can use to calculate recency. Feel free to print the online dataset and the snapshot_date into the Console. The pandas library is loaded as pd, and datetime as dt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Recency, Frequency and Monetary value for each customer \n",
    "datamart = online.groupby(['CustomerID']).agg({\n",
    "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n",
    "    'InvoiceNo': 'count',\n",
    "    'TotalSum': 'sum'})\n",
    "\n",
    "# Rename the columns \n",
    "datamart.rename(columns={'InvoiceDate': 'Recency',\n",
    "                         'InvoiceNo': 'Frequency',\n",
    "                         'TotalSum': 'MonetaryValue'}, inplace=True)\n",
    "# Print top 5 rows\n",
    "print(datamart.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully built a dataset with recency, frequency, and monetary values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 3 groups for Recency and Frequency\n",
    "You will now group the customers into three separate groups based on Recency, and Frequency.\n",
    "\n",
    "The dataset has been loaded as datamart, you can use console to view top rows of it. Also, pandas has been loaded as pd.\n",
    "\n",
    "We will use the result from the exercise in the next one, where you will groups customers based on the MonetaryValue and finally calculate and RFM_Score.\n",
    "\n",
    "Once completed, print the results to the screen to make sure you have successfully created the quartile columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for Recency and Frequency\n",
    "r_labels = range(3, 0, -1); f_labels = range(1, 4)\n",
    "\n",
    "# Assign these labels to three equal percentile groups \n",
    "r_groups = pd.qcut(datamart['Recency'], q=3, labels=r_labels)\n",
    "\n",
    "# Assign these labels to three equal percentile groups \n",
    "f_groups = pd.qcut(datamart['Frequency'], q=3, labels=f_labels)\n",
    "\n",
    "# Create new columns R and F\n",
    "datamart = datamart.assign(R=r_groups.values, F=f_groups.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will now finish the job by assigning customers to three groups based on the MonetaryValue percentiles and then calculate an RFM_Score which is a sum of the R, F, and M values.\n",
    "\n",
    "The datamart has been loaded with the R and F values you have created in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for MonetaryValue\n",
    "m_labels = range(1, 4)\n",
    "\n",
    "# Assign these labels to three equal percentile groups \n",
    "m_groups = pd.qcut(datamart['MonetaryValue'], q=3, labels=m_labels)\n",
    "\n",
    "# Create new column M\n",
    "datamart = datamart.assign(M=m_groups)\n",
    "\n",
    "# Calculate RFM_Score\n",
    "datamart['RFM_Score'] = datamart[['R','F','M']].sum(axis=1)\n",
    "print(datamart['RFM_Score'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating custom segments\n",
    "It's your turn to create a custom segmentation based on RFM_Score values. You will create a function to build segmentation and then assign it to each customer.\n",
    "\n",
    "The dataset with the RFM values, RFM Segment and Score has been loaded as datamart, together with pandas and numpy libraries. Feel free to explore the data in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rfm_level function\n",
    "def rfm_level(df):\n",
    "    if df['RFM_Score'] >= 10:\n",
    "        return 'Top'\n",
    "    elif ((df['RFM_Score'] >= 6) and (df['RFM_Score'] <10)):\n",
    "        return 'Middle'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "# Create a new variable RFM_Level\n",
    "datamart['RFM_Level'] = datamart.apply(rfm_level, axis=1)\n",
    "\n",
    "# Print the header with top 5 rows to the console\n",
    "print(datamart.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                Recency  Frequency  MonetaryValue  R  F  M  RFM_Segment  RFM_Score RFM_Level\n",
    "CustomerID                                                                              \n",
    "12747             3         25         948.70     4  4  4          444       12.0       Top\n",
    "12748             1        888        7046.16     4  4  4          444       12.0       Top\n",
    "12749             4         37         813.45     4  4  4          444       12.0       Top\n",
    "12820             4         17         268.02     4  3  3          433       10.0       Top\n",
    "12822            71          9         146.15     2  2  3          223        7.0    Middle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You have successfully created a custom segment based on RFM Score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average values for each RFM_Level, and return a size of each segment \n",
    "rfm_level_agg = datamart.groupby('RFM_Level').agg({\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "  \n",
    "  \t# Return the size of each segment\n",
    "    'MonetaryValue': ['mean', 'count']\n",
    "}).round(1)\n",
    "\n",
    "# Print the aggregated dataset\n",
    "print(rfm_level_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now fully equipped to apply RFM segmentation to any dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InvoiceNo StockCode                      Description  Quantity         InvoiceDate  UnitPrice  CustomerID         Country InvoiceDay  CohortDay\n",
    "416792     572558     22745       POPPY'S PLAYHOUSE BEDROOM          6 2011-10-25 08:26:00       2.10       14286  United Kingdom 2011-10-25 2011-04-11\n",
    "482904     577485     23196    VINTAGE LEAF MAGNETIC NOTEPAD         1 2011-11-20 11:56:00       1.45       16360  United Kingdom 2011-11-20 2011-09-12\n",
    "263743     560034     23299     FOOD COVER WITH BEADS SET 2          6 2011-07-14 13:35:00       3.75       13933  United Kingdom 2011-07-14 2011-07-14\n",
    "495549     578307    72349B  SET/6 PURPLE BUTTERFLY T-LIGHTS         1 2011-11-23 15:53:00       2.10       17290  United Kingdom 2011-11-23 2011-11-23\n",
    "204384     554656     21756         BATH BUILDING BLOCK WORD         3 2011-05-25 13:36:00       5.95       17663  United Kingdom 2011-05-25 2011-02-25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
